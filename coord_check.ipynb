{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc93041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from mup.shape import set_base_shapes\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "from mup.layer import MuReadout\n",
    "from functools import partial\n",
    "from mup.init import (kaiming_normal_, kaiming_uniform_, normal_,\n",
    "                         trunc_normal_, uniform_, xavier_normal_,\n",
    "                         xavier_uniform_)\n",
    "from mup.coord_check import plot_coord_data, _record_coords\n",
    "from torch.nn.modules.conv import _ConvNd\n",
    "\n",
    "from copy import copy\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = {\n",
    "    'default': lambda x: x,\n",
    "    'const_uniform': partial(uniform_, a=-0.1, b=0.1),\n",
    "    'const_normal': partial(normal_, std=0.1),\n",
    "    'const_trunc_normal': partial(trunc_normal_, std=0.1, a=-0.2, b=0.2),\n",
    "    'xavier_uniform': xavier_uniform_,\n",
    "    'xavier_normal': xavier_normal_,\n",
    "    'kaiming_fan_in_uniform': partial(kaiming_uniform_, mode='fan_in'),\n",
    "    'kaiming_fan_in_normal': partial(kaiming_normal_, mode='fan_in'),\n",
    "    'kaiming_fan_out_uniform': partial(kaiming_uniform_, mode='fan_out'),\n",
    "    'kaiming_fan_out_normal': partial(kaiming_normal_, mode='fan_out')\n",
    "}\n",
    "\n",
    "\n",
    "def init_model(model, sampler):\n",
    "    for param in model.parameters():\n",
    "        if len(param.shape) >= 2:\n",
    "            sampler(param)\n",
    "    return model\n",
    "\n",
    "init_methods = {\n",
    "    k: partial(init_model, sampler=s) for k, s in samplers.items()\n",
    "}\n",
    "\n",
    "def _generate_MLP(width, bias=True, mup=True, batchnorm=False, device='cpu'):\n",
    "    mods = [Linear(3072, width, bias=bias, device=device),\n",
    "            nn.ReLU(),\n",
    "            Linear(width, width, bias=bias, device=device),\n",
    "            nn.ReLU()\n",
    "    ]\n",
    "    if mup:\n",
    "        mods.append(MuReadout(width, 10, bias=bias, readout_zero_init=False, device=device))\n",
    "    else:\n",
    "        mods.append(Linear(width, 10, bias=bias, device=device))\n",
    "    if batchnorm:\n",
    "        mods.insert(1, nn.BatchNorm1d(width, device=device))\n",
    "        mods.insert(4, nn.BatchNorm1d(width, device=device))\n",
    "    model = nn.Sequential(*mods)\n",
    "    return model\n",
    "\n",
    "def generate_MLP(width, bias=True, mup=True, readout_zero_init=True, batchnorm=False, init='default', bias_zero_init=False, base_width=256):\n",
    "    if not mup:\n",
    "        model = _generate_MLP(width, bias, mup, batchnorm)\n",
    "        # set base shapes to model's own shapes, so we get SP\n",
    "        return set_base_shapes(model, None)\n",
    "    # it's important we make `model` first, because of random seed\n",
    "    model = _generate_MLP(width, bias, mup, batchnorm)\n",
    "    base_model = _generate_MLP(base_width, bias, mup, batchnorm, device='meta')\n",
    "    set_base_shapes(model, base_model)\n",
    "    init_methods[init](model)\n",
    "    if readout_zero_init:\n",
    "        readout = list(model.modules())[-1]\n",
    "        readout.weight.data.zero_()\n",
    "        if readout.bias is not None:\n",
    "            readout.bias.data.zero_()\n",
    "    if bias_zero_init:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "    return model\n",
    "\n",
    "\n",
    "def _generate_CNN(width, bias=True, mup=True, batchnorm=False, device='cpu'):\n",
    "    mods = [\n",
    "        nn.Conv2d(3, width, kernel_size=5, bias=bias, device=device),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(width, 2*width, kernel_size=5, bias=bias, device=device),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(2*width*25, width*16, bias=bias, device=device),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(width*16, width*10, bias=bias, device=device),\n",
    "        nn.ReLU(inplace=True),\n",
    "    ]\n",
    "    if mup:\n",
    "        mods.append(MuReadout(width*10, 10, bias=bias, readout_zero_init=False, device=device))\n",
    "    else:\n",
    "        mods.append(nn.Linear(width*10, 10, bias=bias, device=device))\n",
    "    if batchnorm:\n",
    "        mods.insert(1, nn.BatchNorm2d(width, device=device))\n",
    "        mods.insert(5, nn.BatchNorm2d(2*width, device=device))\n",
    "        mods.insert(10, nn.BatchNorm1d(16*width, device=device))\n",
    "        mods.insert(13, nn.BatchNorm1d(10*width, device=device))\n",
    "    return nn.Sequential(*mods)\n",
    "\n",
    "def generate_CNN(width, bias=True, mup=True, readout_zero_init=True, batchnorm=False, init='default', bias_zero_init=False, base_width=8):\n",
    "    if not mup:\n",
    "        model = _generate_CNN(width, bias, mup, batchnorm)\n",
    "        # set base shapes to model's own shapes, so we get SP\n",
    "        return set_base_shapes(model, None)\n",
    "    # it's important we make `model` first, because of random seed\n",
    "    model = _generate_CNN(width, bias, mup, batchnorm)\n",
    "    base_model = _generate_CNN(base_width, bias, mup, batchnorm, device='meta')\n",
    "    set_base_shapes(model, base_model)\n",
    "    init_methods[init](model)\n",
    "    if readout_zero_init:\n",
    "        readout = list(model.modules())[-1]\n",
    "        readout.weight.data.zero_()\n",
    "        if readout.bias is not None:\n",
    "            readout.bias.data.zero_()\n",
    "    if bias_zero_init:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, (nn.Linear, _ConvNd)) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "    return model\n",
    "\n",
    "def get_lazy_models(arch, widths, mup=True, init='kaiming_fan_in_normal', readout_zero_init=True, batchnorm=True, base_width=None):\n",
    "    '''if mup is False, then `init`, `readout_zero_init`, `base_width` don't matter.'''\n",
    "    if arch == 'mlp':\n",
    "        base_width = base_width or 256\n",
    "        generate = generate_MLP\n",
    "    elif arch == 'cnn':\n",
    "        base_width = base_width or 8\n",
    "        generate = generate_CNN\n",
    "    def gen(w):\n",
    "        def f():\n",
    "            model = generate(w, mup=mup, init=init, readout_zero_init=readout_zero_init, batchnorm=batchnorm, base_width=base_width)\n",
    "            return model\n",
    "        return f\n",
    "    return {w: gen(w) for w in widths}\n",
    "\n",
    "\n",
    "def get_train_loader(batch_size, num_workers=0, shuffle=False, train=True, download=False):\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    trainset = datasets.CIFAR10(root='dataset', train=train,\n",
    "                                download=download, transform=transform)\n",
    "    return torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d91400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def _get_coord_data(models, dataloader, optcls, nsteps=3,\n",
    "                dict_in_out=False, flatten_input=False, flatten_output=False, \n",
    "                output_name='loss', lossfn='xent', filter_module_by_name=None,\n",
    "                fix_data=True, cuda=True, nseeds=1, \n",
    "                output_fdict=None, input_fdict=None, param_fdict=None,\n",
    "                show_progress=True):\n",
    "    '''Inner method for `get_coord_data`.\n",
    "\n",
    "    Train the models in `models` with optimizer given by `optcls` and data from\n",
    "    `dataloader` for `nsteps` steps, and record coordinate statistics specified\n",
    "    by `output_fdict`, `input_fdict`, `param_fdict`. By default, only `l1` is\n",
    "    computed for output activations of each module.\n",
    "\n",
    "    Inputs:\n",
    "        models: \n",
    "            a dict of lazy models, where the keys are numbers indicating width.\n",
    "            Each entry of `models` is a function that instantiates a model given\n",
    "            nothing.\n",
    "        dataloader:\n",
    "            an iterator whose elements are either Huggingface style dicts, if\n",
    "            `dict_in_out` is True, or (input, label). If `fix_data` is True\n",
    "            (which is the default), then only the first element of `dataloader`\n",
    "            is used in a loop and the rest of `dataloder` is ignored.\n",
    "        optcls: \n",
    "            a function so that `optcls(model)` gives an optimizer used to train\n",
    "            the model.\n",
    "        nsteps: \n",
    "            number of steps to train the model\n",
    "        dict_in_out:\n",
    "            whether the data loader contains Huggingface-style dict input and\n",
    "            output. Default: False\n",
    "        flatten_input:\n",
    "            if not `dict_in_out`, reshape the input to be\n",
    "            `input.view(input.shape[0], -1)`. Typically used for testing MLPs.\n",
    "        flatten_output:\n",
    "            if not `dict_in_out`, reshape the label to be `label.view(-1,\n",
    "            input.shape[-1])`.\n",
    "        output_name:\n",
    "            if `dict_in_out`, this is the key for the loss value if the output\n",
    "            is a dict. If the output is not a dict, then we assume the first\n",
    "            element of the output is the loss.\n",
    "        lossfn:\n",
    "            loss function to use if not `dict_in_out`. Default is `xent` for\n",
    "            cross entropy loss. Other choices are ['mse', 'nll']\n",
    "        filter_module_by_name:\n",
    "            a function that returns a bool given module names (from\n",
    "            `model.named_modules()`), or None. If not None, then only modules\n",
    "            whose name yields True will be recorded.\n",
    "        cuda:\n",
    "            whether to use cuda or not. Default: True\n",
    "        nseeds:\n",
    "            number of times to repeat the training, each with different seeds.\n",
    "        output_fdict, input_fdict, param_fdict: \n",
    "            function dicts to be used in `_record_coords`. By default, only `l1`\n",
    "            is computed for output activations of each module.\n",
    "        show_progress:\n",
    "            show progress using tqdm.\n",
    "    Output:\n",
    "        a pandas DataFrame containing recorded results. The column names are\n",
    "        `'width', 'module', 't'` as well as names of statistics recorded, such\n",
    "        as `'l1'` (see `FDICT` for other premade statistics that can be\n",
    "        collected).\n",
    "    '''\n",
    "    df = []\n",
    "    if fix_data:\n",
    "        batch = next(iter(dataloader))\n",
    "        dataloader = [batch] * nsteps\n",
    "    if show_progress:\n",
    "        from tqdm import tqdm\n",
    "        pbar = tqdm(total=nseeds * len(models))\n",
    "\n",
    "    for i in range(nseeds):\n",
    "        torch.manual_seed(i)\n",
    "        for width, model in models.items():\n",
    "            model = model()\n",
    "            model = model.train()\n",
    "            if cuda:\n",
    "                model = model.cuda()\n",
    "            optimizer = optcls(model)\n",
    "            for batch_idx, batch in enumerate(dataloader, 1):\n",
    "                remove_hooks = []\n",
    "                # add hooks\n",
    "                for name, module in model.named_modules():\n",
    "                    if filter_module_by_name and not filter_module_by_name(name):\n",
    "                        continue\n",
    "                    remove_hooks.append(module.register_forward_hook(\n",
    "                        _record_coords(df, width, name, batch_idx,\n",
    "                            output_fdict=output_fdict,\n",
    "                            input_fdict=input_fdict,\n",
    "                            param_fdict=param_fdict)))\n",
    "                if dict_in_out:\n",
    "                    if cuda:\n",
    "                        for k, v in batch.items():\n",
    "                            if isinstance(v, torch.Tensor):\n",
    "                                batch[k] = v.cuda()\n",
    "                    outputs = model(**batch)\n",
    "                    loss = outputs[output_name] if isinstance(outputs, dict) else outputs[0]\n",
    "                else:\n",
    "                    (data, target) = batch\n",
    "                    if cuda:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    if flatten_input:\n",
    "                        data = data.view(data.size(0), -1)\n",
    "                    output = model(data)\n",
    "                    if flatten_output:\n",
    "                        output = output.view(-1, output.shape[-1])\n",
    "                    if lossfn == 'xent':\n",
    "                        loss = F.cross_entropy(output, target)\n",
    "                    elif lossfn == 'mse':\n",
    "                        loss = F.mse_loss(output, F.one_hot(target, num_classes=output.size(-1)).float())\n",
    "                    elif lossfn == 'nll':\n",
    "                        loss = F.nll_loss(output, target)\n",
    "                    else:\n",
    "                        raise NotImplementedError()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # remove hooks\n",
    "                for handle in remove_hooks:\n",
    "                    handle.remove()\n",
    "\n",
    "                if batch_idx == nsteps: break\n",
    "            if show_progress:\n",
    "                pbar.update(1)\n",
    "\n",
    "            for name, param in model.named_parameters():\n",
    "                output_dim = param.shape[0]\n",
    "                variance = torch.var(param).item()\n",
    "                print(f\"Model Width {width} Parameter {name} Variance: {variance}\")\n",
    "                print(f\"Model Width {width} Parameter {name} meets muTune Condition: {variance <= (1 / output_dim)}\")\n",
    "                print(f\"Model Width {width} Parameter {name} B-Val: {-math.log(variance)/(2*math.log(output_dim))}\")\n",
    "\n",
    "    if show_progress:\n",
    "        pbar.close()\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "\n",
    "def get_coord_data(models, dataloader, optimizer='sgd', lr=None, mup=True,\n",
    "                    filter_trainable_by_name=None,\n",
    "                    **kwargs):\n",
    "    '''Get coord data for coord check.\n",
    "\n",
    "    Train the models in `models` with data from `dataloader` and optimizer\n",
    "    specified by `optimizer` and `lr` for `nsteps` steps, and record coordinate\n",
    "    statistics specified by `output_fdict`, `input_fdict`, `param_fdict`. By\n",
    "    default, only `l1` is computed for output activations of each module.\n",
    "\n",
    "    This function wraps around `_get_coord_data`, with the main difference being\n",
    "    user can specify common optimizers via a more convenient interface.\n",
    "\n",
    "    Inputs:\n",
    "        models: \n",
    "            a dict of lazy models, where the keys are numbers indicating width.\n",
    "            Each entry of `models` is a function that instantiates a model given\n",
    "            nothing.\n",
    "        dataloader:\n",
    "            an iterator whose elements are either Huggingface style dicts, if\n",
    "            `dict_in_out` is True, or (input, label). If `fix_data` is True\n",
    "            (which is the default), then only the first element of `dataloader`\n",
    "            is used in a loop and the rest of `dataloder` is ignored.\n",
    "        optimizer:\n",
    "            a string in `['sgd', 'adam', 'adamw']`, with default being `'sgd'`.\n",
    "        lr: \n",
    "            learning rate. By default is 0.1 for `'sgd'` and 1e-3 for others.\n",
    "        mup: \n",
    "            If True, then use the optimizer from `mup.optim`; otherwise, use the\n",
    "            one from `torch.optim`.\n",
    "        filter_trainable_by_name: \n",
    "            a function that returns a bool given module names (from\n",
    "            `model.named_modules()`), or None. If not None, then only modules\n",
    "            whose name yields True will be trained.\n",
    "        nsteps: \n",
    "            number of steps to train the model\n",
    "        dict_in_out:\n",
    "            whether the data loader contains Huggingface-style dict input and\n",
    "            output. Default: False\n",
    "        flatten_input:\n",
    "            if not `dict_in_out`, reshape the input to be\n",
    "            `input.view(input.shape[0], -1)`. Typically used for testing MLPs.\n",
    "        flatten_output:\n",
    "            if not `dict_in_out`, reshape the label to be `label.view(-1,\n",
    "            input.shape[-1])`.\n",
    "        output_name:\n",
    "            if `dict_in_out`, this is the key for the loss value if the output\n",
    "            is a dict. If the output is not a dict, then we assume the first\n",
    "            element of the output is the loss.\n",
    "        lossfn:\n",
    "            loss function to use if not `dict_in_out`. Default is `xent` for\n",
    "            cross entropy loss. Other choices are ['mse', 'nll']\n",
    "        filter_module_by_name:\n",
    "            a function that returns a bool given module names (from\n",
    "            `model.named_modules()`), or None. If not None, then only modules\n",
    "            whose name yields True will be recorded.\n",
    "        cuda:\n",
    "            whether to use cuda or not. Default: True\n",
    "        nseeds:\n",
    "            number of times to repeat the training, each with different seeds.\n",
    "        output_fdict, input_fdict, param_fdict: \n",
    "            function dicts to be used in `_record_coords`. By default, only `l1`\n",
    "            is computed for output activations of each module.\n",
    "        show_progress:\n",
    "            show progress using tqdm.\n",
    "    Output:\n",
    "        a pandas DataFrame containing recorded results. The column names are\n",
    "        `'width', 'module', 't'` as well as names of statistics recorded, such\n",
    "        as `'l1'` (see `FDICT` for other premade statistics that can be\n",
    "        collected).\n",
    "    '''\n",
    "    if lr is None:\n",
    "        lr = 0.1 if optimizer == 'sgd' else 1e-3\n",
    "    if mup:\n",
    "        from mup.optim import MuAdam as Adam\n",
    "        from mup.optim import MuAdamW as AdamW\n",
    "        from mup.optim import MuSGD as SGD\n",
    "    else:\n",
    "        from torch.optim import SGD, Adam, AdamW\n",
    "    def get_trainable(model):\n",
    "        params = model.parameters()\n",
    "        if filter_trainable_by_name is not None:\n",
    "            params = []\n",
    "            for name, p in model.named_parameters():\n",
    "                if filter_trainable_by_name(name):\n",
    "                    params.append(p)\n",
    "        return params\n",
    "    if optimizer == 'sgd':\n",
    "        optcls = lambda model: SGD(get_trainable(model), lr=lr)\n",
    "    elif optimizer == 'adam':\n",
    "        optcls = lambda model: Adam(get_trainable(model), lr=lr)\n",
    "    elif optimizer == 'adamw':\n",
    "        optcls = lambda model: AdamW(get_trainable(model), lr=lr)\n",
    "    elif optimizer is None:\n",
    "        raise ValueError('optimizer should be sgd|adam|adamw or a custom function')\n",
    "    \n",
    "    data = _get_coord_data(models, dataloader, optcls, **kwargs)\n",
    "    data['optimizer'] = optimizer\n",
    "    data['lr'] = lr\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44f267af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_plot_coord_check(\n",
    "    arch='mlp', optimizer='sgd', lr=None, widths=None, mup=True,\n",
    "    nsteps=3, nseeds=10, plotdir='', batchnorm=False, batch_size=1,\n",
    "    init='kaiming_fan_in_normal', download_cifar=True, legend='full',\n",
    "    dict_in_out=False, name_contains=None, name_not_contains=None, models=None, train_loader=None):\n",
    "\n",
    "    if batchnorm:\n",
    "        batch_size = 5\n",
    "    if train_loader is None:\n",
    "        train_loader = get_train_loader(batch_size=batch_size, download=download_cifar)\n",
    "\n",
    "    if widths is None:\n",
    "        widths = 2**np.arange(7, 14) if arch == 'mlp' else 2**np.arange(3, 10)\n",
    "    if models is None:\n",
    "        models = get_lazy_models(arch, widths, mup=mup, batchnorm=batchnorm, init=init, readout_zero_init=True)\n",
    "    df = get_coord_data(models, train_loader, mup=mup, lr=lr, optimizer=optimizer, flatten_input=arch == 'mlp', nseeds=nseeds, nsteps=nsteps, dict_in_out=dict_in_out)\n",
    "\n",
    "    prm = 'μP' if mup else 'SP'\n",
    "    bn = 'on' if batchnorm else 'off'\n",
    "    if lr is None:\n",
    "        lr = 0.1 if optimizer == 'sgd' else 1e-3\n",
    "    return plot_coord_data(df, legend=legend,\n",
    "        name_contains=name_contains, name_not_contains=name_not_contains, \n",
    "        save_to=os.path.join(plotdir, f'{prm.lower()}_{arch}_{optimizer}_lr{lr}_nseeds{nseeds}_bn{int(batchnorm)}_coord.png'),\n",
    "        suptitle=f'{prm} {arch.upper()} {optimizer} lr={lr} bn={bn} nseeds={nseeds}',\n",
    "        face_color='xkcd:light grey' if not mup else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace09995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Width 128 Parameter 0.weight Variance: 0.00010944092355202883\n",
      "Model Width 128 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.weight B-Val: 0.9398257192514886\n",
      "Model Width 128 Parameter 0.bias Variance: 0.0001105001792893745\n",
      "Model Width 128 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.bias B-Val: 0.9388331192229389\n",
      "Model Width 128 Parameter 2.weight Variance: 0.0026165926828980446\n",
      "Model Width 128 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.weight B-Val: 0.6127210659135591\n",
      "Model Width 128 Parameter 2.bias Variance: 0.002593505196273327\n",
      "Model Width 128 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.bias B-Val: 0.613634358886789\n",
      "Model Width 128 Parameter 4.weight Variance: 0.0029050589073449373\n",
      "Model Width 128 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.weight B-Val: 1.2684225283880355\n",
      "Model Width 128 Parameter 4.bias Variance: 0.008062114007771015\n",
      "Model Width 128 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.bias B-Val: 1.0467755323524761\n",
      "Model Width 256 Parameter 0.weight Variance: 0.00010899586777668446\n",
      "Model Width 256 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.weight B-Val: 0.8227149336621216\n",
      "Model Width 256 Parameter 0.bias Variance: 0.00011093260400230065\n",
      "Model Width 256 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.bias B-Val: 0.8211268082386969\n",
      "Model Width 256 Parameter 2.weight Variance: 0.0013019073521718383\n",
      "Model Width 256 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.weight B-Val: 0.5990723437018274\n",
      "Model Width 256 Parameter 2.bias Variance: 0.0014633360551670194\n",
      "Model Width 256 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.bias B-Val: 0.5885326976361949\n",
      "Model Width 256 Parameter 4.weight Variance: 0.0014270272804424167\n",
      "Model Width 256 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.weight B-Val: 1.4227838622049895\n",
      "Model Width 256 Parameter 4.bias Variance: 0.005421903450042009\n",
      "Model Width 256 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.bias B-Val: 1.132924110169294\n",
      "Model Width 512 Parameter 0.weight Variance: 0.00010888263932429254\n",
      "Model Width 512 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.weight B-Val: 0.731385468673471\n",
      "Model Width 512 Parameter 0.bias Variance: 0.00011141606228193268\n",
      "Model Width 512 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.bias B-Val: 0.7295419525520849\n",
      "Model Width 512 Parameter 2.weight Variance: 0.0006487878854386508\n",
      "Model Width 512 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.weight B-Val: 0.5883314165900324\n",
      "Model Width 512 Parameter 2.bias Variance: 0.0006799218244850636\n",
      "Model Width 512 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.bias B-Val: 0.5845746389279438\n",
      "Model Width 512 Parameter 4.weight Variance: 0.0006984919309616089\n",
      "Model Width 512 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.weight B-Val: 1.5779193032638679\n",
      "Model Width 512 Parameter 4.bias Variance: 0.0062722982838749886\n",
      "Model Width 512 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.bias B-Val: 1.1012866483154566\n",
      "Model Width 1024 Parameter 0.weight Variance: 0.00010872310667764395\n",
      "Model Width 1024 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.weight B-Val: 0.6583526896930676\n",
      "Model Width 1024 Parameter 0.bias Variance: 0.00010629239841364324\n",
      "Model Width 1024 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.bias B-Val: 0.6599836977243693\n",
      "Model Width 1024 Parameter 2.weight Variance: 0.00032585012377239764\n",
      "Model Width 1024 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.weight B-Val: 0.5791751918297583\n",
      "Model Width 1024 Parameter 2.bias Variance: 0.00035292180837132037\n",
      "Model Width 1024 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.bias B-Val: 0.5734181898551227\n",
      "Model Width 1024 Parameter 4.weight Variance: 0.00036258524050936103\n",
      "Model Width 1024 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.weight B-Val: 1.72029493919334\n",
      "Model Width 1024 Parameter 4.bias Variance: 0.0026618577539920807\n",
      "Model Width 1024 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.bias B-Val: 1.2874075781697611\n",
      "Model Width 2048 Parameter 0.weight Variance: 0.00010859358735615388\n",
      "Model Width 2048 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.weight B-Val: 0.5985806121632546\n",
      "Model Width 2048 Parameter 0.bias Variance: 0.00010685796587495133\n",
      "Model Width 2048 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.bias B-Val: 0.5996371781747478\n",
      "Model Width 2048 Parameter 2.weight Variance: 0.00016278460680041462\n",
      "Model Width 2048 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.weight B-Val: 0.5720340044219803\n",
      "Model Width 2048 Parameter 2.bias Variance: 0.00016640896501485258\n",
      "Model Width 2048 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.bias B-Val: 0.5705899645957311\n",
      "Model Width 2048 Parameter 4.weight Variance: 0.00017718748131301254\n",
      "Model Width 2048 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.weight B-Val: 1.8757834826148214\n",
      "Model Width 2048 Parameter 4.bias Variance: 0.00231576943770051\n",
      "Model Width 2048 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.bias B-Val: 1.3176523409781078\n",
      "Model Width 4096 Parameter 0.weight Variance: 0.00010852043487830088\n",
      "Model Width 4096 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.weight B-Val: 0.5487394018931508\n",
      "Model Width 4096 Parameter 0.bias Variance: 0.00010764030594145879\n",
      "Model Width 4096 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.bias B-Val: 0.549228915955915\n",
      "Model Width 4096 Parameter 2.weight Variance: 8.139436249621212e-05\n",
      "Model Width 4096 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.weight B-Val: 0.5660296499938355\n",
      "Model Width 4096 Parameter 2.bias Variance: 8.115763921523467e-05\n",
      "Model Width 4096 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.bias B-Val: 0.5662047322964032\n",
      "Model Width 4096 Parameter 4.weight Variance: 8.64069297676906e-05\n",
      "Model Width 4096 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.weight B-Val: 2.0317257130245374\n",
      "Model Width 4096 Parameter 4.bias Variance: 0.0009147534146904945\n",
      "Model Width 4096 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.bias B-Val: 1.5193479803284549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Width 8192 Parameter 0.weight Variance: 0.0001085157782654278\n",
      "Model Width 8192 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.weight B-Val: 0.5065310597239044\n",
      "Model Width 8192 Parameter 0.bias Variance: 0.00010797073628054932\n",
      "Model Width 8192 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.bias B-Val: 0.5068104628194822\n",
      "Model Width 8192 Parameter 2.weight Variance: 4.06954568461515e-05\n",
      "Model Width 8192 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.weight B-Val: 0.5609527973210601\n",
      "Model Width 8192 Parameter 2.bias Variance: 4.0979157347464934e-05\n",
      "Model Width 8192 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.bias B-Val: 0.5605673136867183\n",
      "Model Width 8192 Parameter 4.weight Variance: 4.575736966216937e-05\n",
      "Model Width 8192 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.weight B-Val: 2.169769474341325\n",
      "Model Width 8192 Parameter 4.bias Variance: 0.0011639766162261367\n",
      "Model Width 8192 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.bias B-Val: 1.4670278721909875\n",
      "Model Width 128 Parameter 0.weight Variance: 0.00010904034570557997\n",
      "Model Width 128 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.weight B-Val: 0.9402035955937327\n",
      "Model Width 128 Parameter 0.bias Variance: 0.00011899358651135117\n",
      "Model Width 128 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.bias B-Val: 0.9312020401401835\n",
      "Model Width 128 Parameter 2.weight Variance: 0.002617874415591359\n",
      "Model Width 128 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.weight B-Val: 0.6126705996100434\n",
      "Model Width 128 Parameter 2.bias Variance: 0.002666983287781477\n",
      "Model Width 128 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.bias B-Val: 0.6107553928685409\n",
      "Model Width 128 Parameter 4.weight Variance: 0.0028408924117684364\n",
      "Model Width 128 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.weight B-Val: 1.2732726066267477\n",
      "Model Width 128 Parameter 4.bias Variance: 0.002159594325348735\n",
      "Model Width 128 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.bias B-Val: 1.3328139111859152\n",
      "Model Width 256 Parameter 0.weight Variance: 0.00010885070514632389\n",
      "Model Width 256 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.weight B-Val: 0.8228351016289217\n",
      "Model Width 256 Parameter 0.bias Variance: 0.00010956506594084203\n",
      "Model Width 256 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.bias B-Val: 0.8222452813257747\n",
      "Model Width 256 Parameter 2.weight Variance: 0.0013082713121548295\n",
      "Model Width 256 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.weight B-Val: 0.5986326577223752\n",
      "Model Width 256 Parameter 2.bias Variance: 0.0014032592298462987\n",
      "Model Width 256 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.bias B-Val: 0.5923126710061404\n",
      "Model Width 256 Parameter 4.weight Variance: 0.001384544069878757\n",
      "Model Width 256 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.weight B-Val: 1.429346608077456\n",
      "Model Width 256 Parameter 4.bias Variance: 0.006416433956474066\n",
      "Model Width 256 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.bias B-Val: 1.096353135755899\n",
      "Model Width 512 Parameter 0.weight Variance: 0.00010874432337004691\n",
      "Model Width 512 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.weight B-Val: 0.7314873493134555\n",
      "Model Width 512 Parameter 0.bias Variance: 0.0001089789075194858\n",
      "Model Width 512 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.bias B-Val: 0.7313146358905753\n",
      "Model Width 512 Parameter 2.weight Variance: 0.000652527844067663\n",
      "Model Width 512 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.weight B-Val: 0.5878707175110179\n",
      "Model Width 512 Parameter 2.bias Variance: 0.0006597443134523928\n",
      "Model Width 512 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.bias B-Val: 0.5869891871663936\n",
      "Model Width 512 Parameter 4.weight Variance: 0.0007127052522264421\n",
      "Model Width 512 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.weight B-Val: 1.5735450203457657\n",
      "Model Width 512 Parameter 4.bias Variance: 0.0037548590917140245\n",
      "Model Width 512 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.bias B-Val: 1.2127031780435256\n",
      "Model Width 1024 Parameter 0.weight Variance: 0.00010867662786040455\n",
      "Model Width 1024 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.weight B-Val: 0.6583835336866455\n",
      "Model Width 1024 Parameter 0.bias Variance: 0.0001073782259481959\n",
      "Model Width 1024 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.bias B-Val: 0.6592505452430211\n",
      "Model Width 1024 Parameter 2.weight Variance: 0.0003256743948440999\n",
      "Model Width 1024 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.weight B-Val: 0.5792141041426951\n",
      "Model Width 1024 Parameter 2.bias Variance: 0.0003206657711416483\n",
      "Model Width 1024 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.bias B-Val: 0.580332100764592\n",
      "Model Width 1024 Parameter 4.weight Variance: 0.0003549327375367284\n",
      "Model Width 1024 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.weight B-Val: 1.7249269706335582\n",
      "Model Width 1024 Parameter 4.bias Variance: 0.0027493478264659643\n",
      "Model Width 1024 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.bias B-Val: 1.2803851565317028\n",
      "Model Width 2048 Parameter 0.weight Variance: 0.00010854908759938553\n",
      "Model Width 2048 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.weight B-Val: 0.5986074900001097\n",
      "Model Width 2048 Parameter 0.bias Variance: 0.00011249755334574729\n",
      "Model Width 2048 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.bias B-Val: 0.5962644888288458\n",
      "Model Width 2048 Parameter 2.weight Variance: 0.00016280142881441861\n",
      "Model Width 2048 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.weight B-Val: 0.5720272280993586\n",
      "Model Width 2048 Parameter 2.bias Variance: 0.0001583194825798273\n",
      "Model Width 2048 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.bias B-Val: 0.5738578898665283\n",
      "Model Width 2048 Parameter 4.weight Variance: 0.00017742824275046587\n",
      "Model Width 2048 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.weight B-Val: 1.8754886243422977\n",
      "Model Width 2048 Parameter 4.bias Variance: 0.0013489319244399667\n",
      "Model Width 2048 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.bias B-Val: 1.4350049834983976\n",
      "Model Width 4096 Parameter 0.weight Variance: 0.00010845990618690848\n",
      "Model Width 4096 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.weight B-Val: 0.548772939664645\n",
      "Model Width 4096 Parameter 0.bias Variance: 0.00010981295781675726\n",
      "Model Width 4096 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.bias B-Val: 0.5480276699425736\n",
      "Model Width 4096 Parameter 2.weight Variance: 8.14088707556948e-05\n",
      "Model Width 4096 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.weight B-Val: 0.5660189361433153\n",
      "Model Width 4096 Parameter 2.bias Variance: 8.006885764189065e-05\n",
      "Model Width 4096 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.bias B-Val: 0.5670166354709288\n",
      "Model Width 4096 Parameter 4.weight Variance: 8.784968667896464e-05\n",
      "Model Width 4096 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.weight B-Val: 2.0281298915512713\n",
      "Model Width 4096 Parameter 4.bias Variance: 0.0008745302329771221\n",
      "Model Width 4096 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.bias B-Val: 1.5291125860668218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Width 8192 Parameter 0.weight Variance: 0.00010853555431822315\n",
      "Model Width 8192 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.weight B-Val: 0.5065209483925166\n",
      "Model Width 8192 Parameter 0.bias Variance: 0.00010911411663983017\n",
      "Model Width 8192 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.bias B-Val: 0.5062259468126556\n",
      "Model Width 8192 Parameter 2.weight Variance: 4.0698629163671285e-05\n",
      "Model Width 8192 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.weight B-Val: 0.5609484720335034\n",
      "Model Width 8192 Parameter 2.bias Variance: 4.095175245311111e-05\n",
      "Model Width 8192 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.bias B-Val: 0.5606044339935635\n",
      "Model Width 8192 Parameter 4.weight Variance: 4.570106466417201e-05\n",
      "Model Width 8192 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.weight B-Val: 2.1700368411862003\n",
      "Model Width 8192 Parameter 4.bias Variance: 0.0010671199997887015\n",
      "Model Width 8192 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.bias B-Val: 1.4858933702710262\n",
      "Model Width 128 Parameter 0.weight Variance: 0.00010968948481604457\n",
      "Model Width 128 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.weight B-Val: 0.9395919391806425\n",
      "Model Width 128 Parameter 0.bias Variance: 0.00012542733747977763\n",
      "Model Width 128 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.bias B-Val: 0.9257757539249182\n",
      "Model Width 128 Parameter 2.weight Variance: 0.0026556646917015314\n",
      "Model Width 128 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.weight B-Val: 0.6111936630977038\n",
      "Model Width 128 Parameter 2.bias Variance: 0.0025176273193210363\n",
      "Model Width 128 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.bias B-Val: 0.6166942532736313\n",
      "Model Width 128 Parameter 4.weight Variance: 0.002780071459710598\n",
      "Model Width 128 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.weight B-Val: 1.2779720203576654\n",
      "Model Width 128 Parameter 4.bias Variance: 0.011271422728896141\n",
      "Model Width 128 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.bias B-Val: 0.9740106309604776\n",
      "Model Width 256 Parameter 0.weight Variance: 0.0001091903104679659\n",
      "Model Width 256 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.weight B-Val: 0.8225542213847853\n",
      "Model Width 256 Parameter 0.bias Variance: 0.00010659985855454579\n",
      "Model Width 256 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.bias B-Val: 0.8247191784835908\n",
      "Model Width 256 Parameter 2.weight Variance: 0.0013116030022501945\n",
      "Model Width 256 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.weight B-Val: 0.5984033234684832\n",
      "Model Width 256 Parameter 2.bias Variance: 0.0012051532976329327\n",
      "Model Width 256 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.bias B-Val: 0.606035475823191\n",
      "Model Width 256 Parameter 4.weight Variance: 0.0014199732104316354\n",
      "Model Width 256 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.weight B-Val: 1.4238599245237753\n",
      "Model Width 256 Parameter 4.bias Variance: 0.004189442843198776\n",
      "Model Width 256 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.bias B-Val: 1.1889218651533078\n",
      "Model Width 512 Parameter 0.weight Variance: 0.00010884676885325462\n",
      "Model Width 512 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.weight B-Val: 0.7314118776773921\n",
      "Model Width 512 Parameter 0.bias Variance: 0.00011451663158368319\n",
      "Model Width 512 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.bias B-Val: 0.7273419577339552\n",
      "Model Width 512 Parameter 2.weight Variance: 0.0006528227240778506\n",
      "Model Width 512 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.weight B-Val: 0.5878345057031649\n",
      "Model Width 512 Parameter 2.bias Variance: 0.0006502888863906264\n",
      "Model Width 512 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.bias B-Val: 0.588146200644506\n",
      "Model Width 512 Parameter 4.weight Variance: 0.0007246737950481474\n",
      "Model Width 512 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.weight B-Val: 1.569928721467088\n",
      "Model Width 512 Parameter 4.bias Variance: 0.002176585840061307\n",
      "Model Width 512 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.bias B-Val: 1.3311121002446027\n",
      "Model Width 1024 Parameter 0.weight Variance: 0.0001087114360416308\n",
      "Model Width 1024 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.weight B-Val: 0.6583604332505105\n",
      "Model Width 1024 Parameter 0.bias Variance: 0.0001078862915164791\n",
      "Model Width 1024 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.bias B-Val: 0.6589100408972626\n",
      "Model Width 1024 Parameter 2.weight Variance: 0.0003254352486692369\n",
      "Model Width 1024 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.weight B-Val: 0.5792670929164715\n",
      "Model Width 1024 Parameter 2.bias Variance: 0.00033765216358006\n",
      "Model Width 1024 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.bias B-Val: 0.5766087288811356\n",
      "Model Width 1024 Parameter 4.weight Variance: 0.0003591348649933934\n",
      "Model Width 1024 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.weight B-Val: 1.7223712156502216\n",
      "Model Width 1024 Parameter 4.bias Variance: 0.0035004019737243652\n",
      "Model Width 1024 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.bias B-Val: 1.2279410399754058\n",
      "Model Width 2048 Parameter 0.weight Variance: 0.0001085742624127306\n",
      "Model Width 2048 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.weight B-Val: 0.5985922830688135\n",
      "Model Width 2048 Parameter 0.bias Variance: 0.0001069809659384191\n",
      "Model Width 2048 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.bias B-Val: 0.5995617383864669\n",
      "Model Width 2048 Parameter 2.weight Variance: 0.00016275286907330155\n",
      "Model Width 2048 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.weight B-Val: 0.5720467910692534\n",
      "Model Width 2048 Parameter 2.bias Variance: 0.00016421890177298337\n",
      "Model Width 2048 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.bias B-Val: 0.571458735778127\n",
      "Model Width 2048 Parameter 4.weight Variance: 0.00017774863226804882\n",
      "Model Width 2048 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.weight B-Val: 1.8750968661872116\n",
      "Model Width 2048 Parameter 4.bias Variance: 0.0012422017753124237\n",
      "Model Width 2048 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.bias B-Val: 1.4529039272055793\n",
      "Model Width 4096 Parameter 0.weight Variance: 0.00010854354331968352\n",
      "Model Width 4096 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.weight B-Val: 0.5487266028886867\n",
      "Model Width 4096 Parameter 0.bias Variance: 0.00010855585423996672\n",
      "Model Width 4096 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.bias B-Val: 0.5487197853879398\n",
      "Model Width 4096 Parameter 2.weight Variance: 8.140205318341032e-05\n",
      "Model Width 4096 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.weight B-Val: 0.5660239704480852\n",
      "Model Width 4096 Parameter 2.bias Variance: 8.040993998292834e-05\n",
      "Model Width 4096 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.bias B-Val: 0.5667611092216691\n",
      "Model Width 4096 Parameter 4.weight Variance: 8.741513738641515e-05\n",
      "Model Width 4096 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.weight B-Val: 2.0292066777665987\n",
      "Model Width 4096 Parameter 4.bias Variance: 0.001678959932178259\n",
      "Model Width 4096 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.bias B-Val: 1.3874798340160022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Width 8192 Parameter 0.weight Variance: 0.00010851525439647958\n",
      "Model Width 8192 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.weight B-Val: 0.5065313275987952\n",
      "Model Width 8192 Parameter 0.bias Variance: 0.00010992140596499667\n",
      "Model Width 8192 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.bias B-Val: 0.5058169237373717\n",
      "Model Width 8192 Parameter 2.weight Variance: 4.069580609211698e-05\n",
      "Model Width 8192 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.weight B-Val: 0.5609523211260973\n",
      "Model Width 8192 Parameter 2.bias Variance: 4.03776575694792e-05\n",
      "Model Width 8192 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.bias B-Val: 0.5613878175561472\n",
      "Model Width 8192 Parameter 4.weight Variance: 4.5883149141445756e-05\n",
      "Model Width 8192 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.weight B-Val: 2.169173391202541\n",
      "Model Width 8192 Parameter 4.bias Variance: 0.0011510142358019948\n",
      "Model Width 8192 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.bias B-Val: 1.469459652480491\n",
      "Model Width 128 Parameter 0.weight Variance: 0.00010951065632980317\n",
      "Model Width 128 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.weight B-Val: 0.939760079731595\n",
      "Model Width 128 Parameter 0.bias Variance: 0.00012617534957826138\n",
      "Model Width 128 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 0.bias B-Val: 0.9251630211294893\n",
      "Model Width 128 Parameter 2.weight Variance: 0.002654212061315775\n",
      "Model Width 128 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.weight B-Val: 0.6112500459696217\n",
      "Model Width 128 Parameter 2.bias Variance: 0.0024207052774727345\n",
      "Model Width 128 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 2.bias B-Val: 0.6207397745531289\n",
      "Model Width 128 Parameter 4.weight Variance: 0.0029271049425005913\n",
      "Model Width 128 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.weight B-Val: 1.2667808534855434\n",
      "Model Width 128 Parameter 4.bias Variance: 0.01012725941836834\n",
      "Model Width 128 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 128 Parmaeter 4.bias B-Val: 0.9972540325276851\n",
      "Model Width 256 Parameter 0.weight Variance: 0.00010881836351472884\n",
      "Model Width 256 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.weight B-Val: 0.8228618963821605\n",
      "Model Width 256 Parameter 0.bias Variance: 9.566226071910933e-05\n",
      "Model Width 256 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 0.bias B-Val: 0.8344806617818588\n",
      "Model Width 256 Parameter 2.weight Variance: 0.001300276373513043\n",
      "Model Width 256 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.weight B-Val: 0.5991853740149705\n",
      "Model Width 256 Parameter 2.bias Variance: 0.0013742286246269941\n",
      "Model Width 256 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 2.bias B-Val: 0.5941976403401547\n",
      "Model Width 256 Parameter 4.weight Variance: 0.0013916337629780173\n",
      "Model Width 256 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.weight B-Val: 1.4282375216030798\n",
      "Model Width 256 Parameter 4.bias Variance: 0.0060373651795089245\n",
      "Model Width 256 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 256 Parmaeter 4.bias B-Val: 1.1095762771843214\n",
      "Model Width 512 Parameter 0.weight Variance: 0.00010880167246796191\n",
      "Model Width 512 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.weight B-Val: 0.7314450914499022\n",
      "Model Width 512 Parameter 0.bias Variance: 0.00011669037485262379\n",
      "Model Width 512 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 0.bias B-Val: 0.7258348229765337\n",
      "Model Width 512 Parameter 2.weight Variance: 0.0006523411138914526\n",
      "Model Width 512 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.weight B-Val: 0.5878936567834848\n",
      "Model Width 512 Parameter 2.bias Variance: 0.0006439766148105264\n",
      "Model Width 512 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 2.bias B-Val: 0.588928004438268\n",
      "Model Width 512 Parameter 4.weight Variance: 0.0007077422924339771\n",
      "Model Width 512 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.weight B-Val: 1.5750624257794652\n",
      "Model Width 512 Parameter 4.bias Variance: 0.003634117543697357\n",
      "Model Width 512 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 512 Parmaeter 4.bias B-Val: 1.2198005148825164\n",
      "Model Width 1024 Parameter 0.weight Variance: 0.0001086310512619093\n",
      "Model Width 1024 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.weight B-Val: 0.6584137917676575\n",
      "Model Width 1024 Parameter 0.bias Variance: 0.00011422430543461815\n",
      "Model Width 1024 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 0.bias B-Val: 0.6547921354796482\n",
      "Model Width 1024 Parameter 2.weight Variance: 0.0003259691293351352\n",
      "Model Width 1024 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.weight B-Val: 0.5791488518994344\n",
      "Model Width 1024 Parameter 2.bias Variance: 0.000342922518029809\n",
      "Model Width 1024 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 2.bias B-Val: 0.5754914868750092\n",
      "Model Width 1024 Parameter 4.weight Variance: 0.0003633668238762766\n",
      "Model Width 1024 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.weight B-Val: 1.7198273635899322\n",
      "Model Width 1024 Parameter 4.bias Variance: 0.002751241670921445\n",
      "Model Width 1024 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 1024 Parmaeter 4.bias B-Val: 1.2802356296074542\n",
      "Model Width 2048 Parameter 0.weight Variance: 0.00010859436588361859\n",
      "Model Width 2048 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.weight B-Val: 0.5985801420309879\n",
      "Model Width 2048 Parameter 0.bias Variance: 0.00010921589273493737\n",
      "Model Width 2048 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 0.bias B-Val: 0.5982058896278233\n",
      "Model Width 2048 Parameter 2.weight Variance: 0.00016280540148727596\n",
      "Model Width 2048 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.weight B-Val: 0.5720256279108387\n",
      "Model Width 2048 Parameter 2.bias Variance: 0.00016275254893116653\n",
      "Model Width 2048 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 2.bias B-Val: 0.5720469200623501\n",
      "Model Width 2048 Parameter 4.weight Variance: 0.00017861583910416812\n",
      "Model Width 2048 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.weight B-Val: 1.8740400159193338\n",
      "Model Width 2048 Parameter 4.bias Variance: 0.001595351379364729\n",
      "Model Width 2048 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 2048 Parmaeter 4.bias B-Val: 1.3985718239170488\n",
      "Model Width 4096 Parameter 0.weight Variance: 0.00010846726218005642\n",
      "Model Width 4096 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.weight B-Val: 0.5487688628528594\n",
      "Model Width 4096 Parameter 0.bias Variance: 0.0001099437358789146\n",
      "Model Width 4096 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 0.bias B-Val: 0.5479561238154943\n",
      "Model Width 4096 Parameter 2.weight Variance: 8.142586011672392e-05\n",
      "Model Width 4096 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.weight B-Val: 0.5660063925114674\n",
      "Model Width 4096 Parameter 2.bias Variance: 8.187310595531017e-05\n",
      "Model Width 4096 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 2.bias B-Val: 0.5656771186534979\n",
      "Model Width 4096 Parameter 4.weight Variance: 8.716372394701466e-05\n",
      "Model Width 4096 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.weight B-Val: 2.0298321117054865\n",
      "Model Width 4096 Parameter 4.bias Variance: 0.0014431154122576118\n",
      "Model Width 4096 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 4096 Parmaeter 4.bias B-Val: 1.42034946754324\n",
      "Model Width 8192 Parameter 0.weight Variance: 0.0001085230105672963\n",
      "Model Width 8192 Parameter 0.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.weight B-Val: 0.506527361694378\n",
      "Model Width 8192 Parameter 0.bias Variance: 0.00010995622869813815\n",
      "Model Width 8192 Parameter 0.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 0.bias B-Val: 0.5057993480228995\n",
      "Model Width 8192 Parameter 2.weight Variance: 4.069615533808246e-05\n",
      "Model Width 8192 Parameter 2.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.weight B-Val: 0.5609518449352213\n",
      "Model Width 8192 Parameter 2.bias Variance: 4.079893551534042e-05\n",
      "Model Width 8192 Parameter 2.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 2.bias B-Val: 0.5608118831958592\n",
      "Model Width 8192 Parameter 4.weight Variance: 4.582682959153317e-05\n",
      "Model Width 8192 Parameter 4.weight meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.weight B-Val: 2.16944009361773\n",
      "Model Width 8192 Parameter 4.bias Variance: 0.000847465533297509\n",
      "Model Width 8192 Parameter 4.bias meets muTune Condition: True\n",
      "Model Width 8192 Parmaeter 4.bias B-Val: 1.5359389778326984\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arch, opt, bn, mup \u001b[38;5;129;01min\u001b[39;00m product([\u001b[33m'\u001b[39m\u001b[33mmlp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m'\u001b[39m], [\u001b[33m'\u001b[39m\u001b[33msgd\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m], [\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m], [\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m]):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mexample_plot_coord_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnseeds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_cifar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mplotdir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcoord_checks/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     plt.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mexample_plot_coord_check\u001b[39m\u001b[34m(arch, optimizer, lr, widths, mup, nsteps, nseeds, plotdir, batchnorm, batch_size, init, download_cifar, legend, dict_in_out, name_contains, name_not_contains, models, train_loader)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m models \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m     models = get_lazy_models(arch, widths, mup=mup, batchnorm=batchnorm, init=init, readout_zero_init=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m df = \u001b[43mget_coord_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43march\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmlp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnseeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnsteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_in_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdict_in_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m prm = \u001b[33m'\u001b[39m\u001b[33mμP\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mup \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mSP\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m bn = \u001b[33m'\u001b[39m\u001b[33mon\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batchnorm \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 236\u001b[39m, in \u001b[36mget_coord_data\u001b[39m\u001b[34m(models, dataloader, optimizer, lr, mup, filter_trainable_by_name, **kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33moptimizer should be sgd|adam|adamw or a custom function\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m data = \u001b[43m_get_coord_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m'\u001b[39m] = optimizer\n\u001b[32m    238\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = lr\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36m_get_coord_data\u001b[39m\u001b[34m(models, dataloader, optcls, nsteps, dict_in_out, flatten_input, flatten_output, output_name, lossfn, filter_module_by_name, fix_data, cuda, nseeds, output_fdict, input_fdict, param_fdict, show_progress)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flatten_input:\n\u001b[32m    104\u001b[39m     data = data.view(data.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flatten_output:\n\u001b[32m    107\u001b[39m     output = output.view(-\u001b[32m1\u001b[39m, output.shape[-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:133\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/muTune/.venv/lib/python3.12/site-packages/torch/nn/functional.py:1704\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1702\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1703\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for arch, opt, bn, mup in product(['mlp', 'cnn'], ['sgd', 'adam'], [False, True], [False, True]):\n",
    "    example_plot_coord_check(arch, opt, batchnorm=bn, mup=mup, nseeds=5, download_cifar=True, legend=None,\n",
    "                    plotdir='coord_checks/')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
